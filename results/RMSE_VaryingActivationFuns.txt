Activation Function: Sigmoid	RMSE Train: (100, 1.010171890258789)
Activation Function: ReLU	RMSE Train: (100, 1.010161280632019)
Activation Function: Tanh	RMSE Train: (100, 1.0101861953735352)

Activation Function: Sigmoid	RMSE Dev: (100, 1.0051583051681519)
Activation Function: ReLU	RMSE Dev: (100, 1.005192518234253)
Activation Function: Tanh	RMSE Dev: (100, 1.0052027702331543)

Activation Function: Sigmoid	 Precision: 0.8674069289030846
Activation Function: ReLU	 Precision: 0.8674069289030846
Activation Function: Tanh	 Precision: 0.8674069289030846

Activation Function: Sigmoid	 Recall: 0.8913453326703361
Activation Function: ReLU	 Recall: 0.8913453326703361
Activation Function: Tanh	 Recall: 0.8913453326703361

Activation Function: Sigmoid	 F1: 0.8792132177979273
Activation Function: ReLU	 F1: 0.8792132177979273
Activation Function: Tanh	 F1: 0.8792132177979273
